# Codes-for-Algorithms
- Codes for realizing theories learned from Data Mining, Machine Learning, Deep Learning without using the present Python packages. (Just basic coding test to challenge myself).
- **Upload on a random basis.**

--------

1. Junior Data Processing
  - Calculate Distance **N dimensional vector**:
    - [x] euclidean
    - [x] manhattan
    - [x] Minkowski
  - Calculate Similarity: 
    - [x] Jaccard
    - [x] Simple Matching Coefficent(SMC) 
  - Calculate relevance:
    - [x] Covariance
    - [x] Sample Standard Deviation (ssd)
    - [x] Pearson Coeffiencent 
2. Models
  - Linear
    - [x] Batch Gradient Descent Regression 
    - Features:
      1. with **Square Loss Function**
      2. Fit for Simple Linear Regression &ã€€Multi-variate Regression
      4. Plot Loss Function & Compare Yhat and YReal

    - [ ] Mini Batch Gradient Descent Regression **Working on Progress** ğŸ¦¾
  - Classification
    - Decision Tree 
     - [x] Entropy: Compute the uncertainty of DateSet 
     - [ ] Information Gain
     - [ ] Decision Tree Visualization **Working on Progress** ğŸ¦¾
     - [x] ID3 
     - [ ] C4.5 **Working on Progress** ğŸ¦¾
    - Bayes
     - [ ] Naive Bayes **Working on Progress** ğŸ¦¾
    - Sigmoid
     - [ ] Logistic Regression **Working on Progress** ğŸ¦¾
  - Cluster
    - [x] K-Nearest Neighbor
        - Kè¿‘é‚»ç®—æ³•
          - â€œç‰©ä»¥ç±»èšï¼Œäººä»¥ç¾¤åˆ†â€æ€æƒ³
          - â€œå°‘æ•°æœä»å¤šæ•°â€æ€æƒ³
            - è‹¥æ— æ³•åˆ¤å®šå±äºå“ªä¸ªç±»ï¼Œå°±å½’ä¸ºæƒé‡å¤§çš„ç±»
        - è¦ç´ 
          1. è·ç¦»
          2. Kå€¼
            - Kå€¼é€‰æ‹©
            1. If Kå€¼è¾ƒå° then è·ç¦»å¾ˆè¿‘æ‰èƒ½è¿›è¡Œé¢„æµ‹ï¼Œç”±äºå…·æœ‰å™ªå£°ï¼Œæ•´ä½“æ¨¡å‹è¿‡äºå¤æ‚ï¼Œä¼šå‘ç”Ÿè¿‡æ‹Ÿåˆç°è±¡
            2. IF Kå€¼è¾ƒå¤§ then è¿‘ä¼¼è¯¯å·®ä¼šè¾ƒå¤§ï¼Œä¸ç›¸ä¼¼ç‚¹å½’ä¸ºåŒä¸€ç±»ï¼Œé¢„æµ‹é”™è¯¯ï¼Œæ¨¡å‹è¿‡äºç®€å•
            3. If K = Nï¼Œä¿¡æ¯å¤§é‡æŸå¤±ï¼Œæ¨¡å‹è¿‡äºç®€å•
              - ç”¨cross validation æ¥é€‰æ‹©æœ€ä¼˜çš„kå€¼
          3. åˆ†ç±»å†³ç­–è§„åˆ™
          - å¤šæ•°è¡¨å†³æ³•
            - æ³¨ï¼šè®¡ç®—è·ç¦»æ—¶på€¼ä¸åŒæœ€é‚»è¿‘ç‚¹ä¼šä¸åŒã€‚
        - ç®—æ³•åŸç†
          - input: å¸¦ç±»æ ‡è®°çš„æ ·æœ¬æ•°æ®é›†åˆï¼›æ²¡æœ‰æ ‡ç­¾çš„æ•°æ®
          - process: å°†å‹æ•°æ®çš„æ¯ä¸ªç‰¹å¾ä¸æ ·æœ¬é›†çš„ç‰¹å¾æ¯”è¾ƒï¼Œæå–å‰Kä¸ªæœ€ç›¸ä¼¼çš„æ ‡ç­¾
          - output: æ–°åˆ†ç±»ç»“æœ
          1. è®¡ç®—trainingä¸­çš„ç‚¹ä¸å½“å‰ç‚¹çš„è·ç¦»
          2. æŒ‰è·ç¦»é€’å¢æ’åº
          3. é€‰å–ä¸å½“å‰ç‚¹è·ç¦»æœ€å°çš„kä¸ªç‚¹
          4. ç»Ÿè®¡å‰kä¸ªç‚¹ä¸­æ¯ä¸€ç±»çš„é¢‘ç‡
          5. è¿”å›é¢‘ç‡æœ€å¤§çš„trainingä¸­çš„ç‚¹çš„ç±»åˆ«
          6. ç»Ÿè®¡åˆ†ç±»é”™è¯¯ç‡
        - Tricks for Data Analysis
          - è¾“å‡ºåˆ†ç±»ç»“æœä¹‹åï¼Œåšåˆ†ç±»é”™è¯¯ç‡ç»Ÿè®¡
          - æ•°æ®é¢„å¤„ç†-> æ•°æ®å¯è§†åŒ–ï¼šåŸå§‹æ•°æ®çš„åˆ†ç±»ç»“æœ
          - ç”¨Kè¿‘é‚»å»ºæ¨¡ï¼Œè®¡ç®—é”™è¯¯ç‡
          - çœ‹é”™è¯¯ç‡è°ƒæ•´Kå€¼
            - Kè¿‘é‚»å—æ•°å€¼çš„å½±å“è¾ƒå¤§ï¼Œå¯¹æ•°æ®è¿›è¡Œå½’ä¸€åŒ–å¤„ç† new = (old - min)/(max - min)
            - train_test_split,æ£€éªŒå‡†ç¡®ç‡
            - è°ƒæ•´æµ‹è¯•æ•°æ®æ¯”ä¾‹æˆ–è€…Kæ¥è°ƒå‚
#### <div align="center"><font color='#00338D'>â€œæˆ‘æ— åšä¸æ‘§ å°†æƒ…è—å¾—éšæ™¦ åªæœ‰é‚£æ˜æœˆ çŸ¥é“è¿‡ç¨‹å£®çƒˆâ€</font></div> 
    - [ ] KMeans
    - [x] Apriori
    - [x] FPGrowth  
  - Neural Network **Working on Progress** ğŸ‘»ğŸ‘»ğŸ‘»ğŸ‘»

---
- **Hope that there's 0.1% possibility that I could start my journey to Computer Vision.**
  - By Tracy Tao (Dasein), a STEM GIRL in business world.
---
Post Scrpits:
- By the way, I wanna shout out loud that I love Elon Musk! ğŸ§ 

    
