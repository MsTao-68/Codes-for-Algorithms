{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60aab68c-462f-4d6c-9258-a2dbf4f9844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !usr/bin/python\n",
    "# -*- encoding: utf-8 -*-\n",
    "# Project: Convolutional Neural Network\n",
    "# Author: Tracy Tao\n",
    "# Date: 2022/04/10\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cf5d740-36fe-4d5e-a61c-2200d1adf09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d(X, Kernel): #@save\n",
    "    '''\n",
    "    :param X: image pixel\n",
    "    :param Kernel: 卷积核；滤波器\n",
    "    function: 2 dimensional cross-correlation\n",
    "    return: 卷积运算之后的结果\n",
    "    '''\n",
    "    height, width = Kernel.shape # 获取图像高和宽\n",
    "    Y = torch.zeros((X.shape[0] - height + 1, X.shape[1] -  width + 1)) # 套用公式，初始化结果矩阵\n",
    "    for i in range(Y.shape[0]): # 遍历矩阵每一行\n",
    "        for j in range(Y.shape[1]): # 遍历矩阵每一列\n",
    "            Y[i,j] = (X[i: i+height, j:j+width] * Kernel).sum() # 按元素乘法求和\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dc49f3a-8e3b-4261-8851-c80422424382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 25.],\n",
       "        [37., 43.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
    "corr2d(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2eb5368c-11ec-4d66-a3be-a6495d61348b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(nn.Module):\n",
    "    '''使用Module构造卷积类'''\n",
    "    def __init__(self, kernel_size):\n",
    "        '''继承module并进行参数初始化'''\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.rand(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return corr2d(x, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e20b8dae-320b-48e9-8d3f-0cb95cfe51fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.ones((6,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe7d2c8f-01f9-410b-bd1b-7dc05e461607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:, 2:6] = 0\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6646b430-e020-4c00-8a37-31b39e4d183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = torch.tensor([[1.0, -1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6249e25a-7709-447e-b622-545e364d716d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = corr2d(X, kernel)\n",
    "Y # 检测垂直边缘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b96b17b3-9160-4826-ae05-435298194ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d(X.t(), kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8537e75f-945a-49c1-829f-c4f929ce1315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#学习卷积核：在每次迭代中，我们比较Y与卷积层输出的平方误差，然后计算梯度来更新卷积核。\n",
    "\n",
    "# 构造一个二维卷积层，它具有1个输出通道和形状为（1，2）的卷积核，并忽略偏置。\n",
    "conv2d = nn.Conv2d(1,1, kernel_size=(1, 2), bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4418392-d360-4ae2-93e2-ebced1497d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 1, kernel_size=(1, 2), stride=(1, 1), bias=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9fa6f3f1-6c2c-476f-a67f-fb2e5658be34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 四维输入和输出格式（批量大小、通道、高度、宽度），\n",
    "X = X.reshape((1, 1, 6, 8))\n",
    "Y = Y.reshape((1, 1, 6, 7))\n",
    "lr = 3e-2  # 学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e1f77b5-66a7-4a0a-8ea7-8022d8572f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 3.439\n",
      "epoch 2, loss 1.409\n",
      "epoch 3, loss 0.577\n",
      "epoch 4, loss 0.236\n",
      "epoch 5, loss 0.097\n",
      "epoch 6, loss 0.040\n",
      "epoch 7, loss 0.016\n",
      "epoch 8, loss 0.007\n",
      "epoch 9, loss 0.003\n",
      "epoch 10, loss 0.001\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    Y_hat = conv2d(X) # 进行卷积运算求y帽子\n",
    "    l = (Y_hat - Y) ** 2 # 计算残差平方和\n",
    "    conv2d.zero_grad() # 初始化梯度\n",
    "    l.sum().backward() # 求梯度\n",
    "    conv2d.weight.data[:] -= lr * conv2d.weight.grad # 反向传播更新卷积核\n",
    "    print(f'epoch {i+1}, loss {l.sum():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2bd8ae96-a152-4839-9191-268051af2fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9934, -0.9942]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.weight.data.reshape((1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513f5561-d9a6-440c-aaf6-0b30bb32505e",
   "metadata": {},
   "source": [
    "- kernel = torch.tensor([[1.0, -1.0]]) 接近定义的k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a318a154-3249-4555-a97b-94bbb2cd3136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding\n",
    "def compute_conv2d(conv2d, X):\n",
    "    '''\n",
    "    :param conv2d: 二维卷积核对象\n",
    "    :param X: 输入矩阵\n",
    "    function: 卷积运算并reshape\n",
    "    return Y\n",
    "    '''\n",
    "    X = X.reshape((1,1) + X.shape) # （1，1）表示批量大小和通道数都是1\n",
    "    Y = conv2d(X)\n",
    "    return Y.reshape(Y.shape[2:]) # 省略前两个维度：批量大小和通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "75b6186b-672f-496b-b186-cf8ecc7f51c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1,1,kernel_size = 3, padding =1) \n",
    "conv2d # 高度为3，宽度为1的卷积核，高度填充1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d585da6f-5c6f-4c96-b425-3de32a0ddd1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7396, 0.8041, 0.0930, 0.6666, 0.3840, 0.0064, 0.5289, 0.5827],\n",
       "        [0.9123, 0.0828, 0.5479, 0.8958, 0.7478, 0.2029, 0.0101, 0.6377],\n",
       "        [0.1328, 0.8036, 0.8145, 0.1376, 0.7164, 0.4953, 0.3401, 0.3980],\n",
       "        [0.5415, 0.6714, 0.7197, 0.1684, 0.2576, 0.5287, 0.8991, 0.2026],\n",
       "        [0.8565, 0.0918, 0.8069, 0.4115, 0.8803, 0.1885, 0.3074, 0.9184],\n",
       "        [0.3165, 0.3509, 0.5189, 0.3935, 0.1815, 0.0569, 0.7506, 0.9154],\n",
       "        [0.9350, 0.9608, 0.2103, 0.7720, 0.9249, 0.8598, 0.9749, 0.7319],\n",
       "        [0.9839, 0.4489, 0.8695, 0.9849, 0.6791, 0.3685, 0.8929, 0.7662]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(size=(8,8))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "519dd857-4084-4a0c-a9ba-bb9e653d331f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0943,  0.1016,  0.3790, -0.0425, -0.0115,  0.0035,  0.0859,  0.0667],\n",
       "        [ 0.4600,  0.4985, -0.1226,  0.3465,  0.2424,  0.1764,  0.3253, -0.0366],\n",
       "        [ 0.3854, -0.0013,  0.3502,  0.5027,  0.1907,  0.2340,  0.1127,  0.0825],\n",
       "        [ 0.1323,  0.5019,  0.2893,  0.2906,  0.2233,  0.0676,  0.3268,  0.1912],\n",
       "        [ 0.2779,  0.5621,  0.0941,  0.1532,  0.1509,  0.6839,  0.3906, -0.2625],\n",
       "        [ 0.3582, -0.0478,  0.3393,  0.4011,  0.2877,  0.0278,  0.1298,  0.1177],\n",
       "        [ 0.1119,  0.3170,  0.5071, -0.0131,  0.0157,  0.3968,  0.5809,  0.1533],\n",
       "        [ 0.4059,  0.4821,  0.1945,  0.5828,  0.5937,  0.5340,  0.3785,  0.2926]],\n",
       "       grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_conv2d(conv2d, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b1f8558-9d66-4268-8696-b039bb3225e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape((1,1) + X.shape)\n",
    "Y = conv2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "42dd60ce-1286-4d65-992b-c0fb95a4b1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e439cf98-10b7-4ec0-93c0-b1645d1eab00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 8, 8]),\n",
       " tensor([[-0.0943,  0.1016,  0.3790, -0.0425, -0.0115,  0.0035,  0.0859,  0.0667],\n",
       "         [ 0.4600,  0.4985, -0.1226,  0.3465,  0.2424,  0.1764,  0.3253, -0.0366],\n",
       "         [ 0.3854, -0.0013,  0.3502,  0.5027,  0.1907,  0.2340,  0.1127,  0.0825],\n",
       "         [ 0.1323,  0.5019,  0.2893,  0.2906,  0.2233,  0.0676,  0.3268,  0.1912],\n",
       "         [ 0.2779,  0.5621,  0.0941,  0.1532,  0.1509,  0.6839,  0.3906, -0.2625],\n",
       "         [ 0.3582, -0.0478,  0.3393,  0.4011,  0.2877,  0.0278,  0.1298,  0.1177],\n",
       "         [ 0.1119,  0.3170,  0.5071, -0.0131,  0.0157,  0.3968,  0.5809,  0.1533],\n",
       "         [ 0.4059,  0.4821,  0.1945,  0.5828,  0.5937,  0.5340,  0.3785,  0.2926]],\n",
       "        grad_fn=<ReshapeAliasBackward0>),\n",
       " tensor([[[[-0.0943,  0.1016,  0.3790, -0.0425, -0.0115,  0.0035,  0.0859,\n",
       "             0.0667],\n",
       "           [ 0.4600,  0.4985, -0.1226,  0.3465,  0.2424,  0.1764,  0.3253,\n",
       "            -0.0366],\n",
       "           [ 0.3854, -0.0013,  0.3502,  0.5027,  0.1907,  0.2340,  0.1127,\n",
       "             0.0825],\n",
       "           [ 0.1323,  0.5019,  0.2893,  0.2906,  0.2233,  0.0676,  0.3268,\n",
       "             0.1912],\n",
       "           [ 0.2779,  0.5621,  0.0941,  0.1532,  0.1509,  0.6839,  0.3906,\n",
       "            -0.2625],\n",
       "           [ 0.3582, -0.0478,  0.3393,  0.4011,  0.2877,  0.0278,  0.1298,\n",
       "             0.1177],\n",
       "           [ 0.1119,  0.3170,  0.5071, -0.0131,  0.0157,  0.3968,  0.5809,\n",
       "             0.1533],\n",
       "           [ 0.4059,  0.4821,  0.1945,  0.5828,  0.5937,  0.5340,  0.3785,\n",
       "             0.2926]]]], grad_fn=<ThnnConv2DBackward0>))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape,Y.reshape(Y.shape[2:]),Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2f9e2479-48a6-4214-8a53-56cdf7846716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1, 1, kernel_size=(5, 3), padding=(2, 1)) \n",
    "# 高度为5，宽度为3的卷积核，高度和宽度两边的填充分别为2和1。\n",
    "X = torch.rand(size=(8,8))\n",
    "compute_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bb988b48-0bfb-4d36-a066-4e0dc7aa263a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stride 垂直步幅和水平步幅\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1, stride=2)\n",
    "X = torch.rand(size=(8,8))\n",
    "compute_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbe7be3-2ad7-4e49-9a54-bdae61c83525",
   "metadata": {},
   "source": [
    "1. 彩色图像具有标准的RGB通道来代表红、绿和蓝\n",
    "    - 每个RGB输入图像具有的形状。我们将这个大小为的轴称为通道（channel）维度\n",
    "2. 输入X的通道数要和kernel的通道数保持一致，因为分别做卷积将返回的结果矩阵相加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d0df418c-c470-4aeb-b1e5-6b1faca138f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in(X, kernel):\n",
    "    '''多通道需要对每一个通道的维度进行卷积运算，最后相加'''\n",
    "    return sum(d2l.corr2d(x, kernel) for x,kernel in zip(X,kernel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e6bc8e04-d70f-4987-9cf1-75bfabf8a6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  72.],\n",
       "        [104., 120.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n",
    "               [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n",
    "K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n",
    "\n",
    "corr2d_multi_in(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c605d82c-e2fc-4db2-8d11-3586da3b46c4",
   "metadata": {},
   "source": [
    "- 多输出通道\n",
    "    - 用和分别表示输入ci和输出co通道的数目，并让和为卷积核的高度kh和宽度kw\n",
    "        - 卷积核形状 co * ci * kh * kw\n",
    "        - 输出通道的卷积核  ci * kh * kw\n",
    "        - 每个输出通道先获取所有输入通道，再以对应该输出通道的卷积核计算出结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8c72b57b-ba42-4cc4-9224-153510ef756a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out(X,K):\n",
    "    '''在每一个维度进行卷积，并将卷积结果叠加'''\n",
    "    return torch.stack([corr2d_multi_in(X,k) for k in K],0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329817c4-20a2-466b-a66b-5d33381f8dfc",
   "metadata": {},
   "source": [
    "- torch.stack（tensors,dim=0,out=None）在维度上连接（concatenate）若干个张量。(这些张量形状相同）。\n",
    "- https://blog.csdn.net/realcoder/article/details/105846408#:~:text=torch.stack%20%28%29%20%E5%87%BD%E6%95%B0%20%EF%BC%9A%20torch.stack%20%28sequence%2C%20dim%3D0%29%201.%E5%87%BD%E6%95%B0,%E8%BF%94%E5%9B%9E%E7%9A%84%E7%BB%93%E6%9E%9C%E4%BC%9A%E6%96%B0%E5%A2%9E%E4%B8%80%E4%B8%AA%E7%BB%B4%E5%BA%A6%EF%BC%8C%E8%80%8C%20stack%EF%BC%88%EF%BC%89%E5%87%BD%E6%95%B0%20%E6%8C%87%E5%AE%9A%E7%9A%84dim%E5%8F%82%E6%95%B0%EF%BC%8C%E5%B0%B1%E6%98%AF%E6%96%B0%E5%A2%9E%E7%BB%B4%E5%BA%A6%E7%9A%84%20%EF%BC%88%20%E4%B8%8B%E6%A0%87%20%EF%BC%89%20%E4%BD%8D%E7%BD%AE%E3%80%82%202."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "15aa80cb-550a-47db-883c-58b467a8ef00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2, 2])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = torch.stack((K, K + 1, K + 2), 0)\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5bac27b7-8eaf-45c5-a1f3-fa0f0b643703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 56.,  72.],\n",
       "         [104., 120.]],\n",
       "\n",
       "        [[ 76., 100.],\n",
       "         [148., 172.]],\n",
       "\n",
       "        [[ 96., 128.],\n",
       "         [192., 224.]]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in_out(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ed8b3d-0c97-408a-8632-c46b4f78b955",
   "metadata": {},
   "source": [
    "- 卷积的本质是有效提取相邻像素间的相关特征，**卷积层通常用于调整网络层的通道数量和控制模型复杂性。**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741ee6f9-cf67-43ee-8f79-9c338ca887b7",
   "metadata": {},
   "source": [
    "1. pooling 降低卷积层对位置的敏感性，同时降低对空间降采样表示的敏感性\n",
    "    - max pooling, avg pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c3ff29aa-1266-42d7-89d5-f6b83e2ec14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool2d(X, pool_size, mode='max'):\n",
    "    '''\n",
    "    :param X: inputs\n",
    "    :param pool_size: (p_h, p_w)\n",
    "    :param mode: 'max'|'avg'\n",
    "    return Y: outputs\n",
    "    '''\n",
    "    p_h, p_w = pool_size\n",
    "    Y = torch.zeros((X.shape[0] - p_h +1, X.shape[1] - p_w +1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i,j] = X[i: i + p_h, j: j + p_w].max()\n",
    "            elif mode == 'avg':\n",
    "                Y[i,j] = X[i: i + p_h, j: j + p_w].mean()\n",
    "    return Y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f61519ba-4266-487d-8f0a-462e08908cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "pool2d(X, (2, 2),'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "01240cbc-ff2f-4b3a-b4aa-c639b6dbe23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d(X, (2, 2), 'avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8a5dd7a5-42f5-4a05-9855-9603bfda5d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[10.]]]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4))\n",
    "pool2d = nn.MaxPool2d(3)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "07460e0c-5f78-49ec-af28-8fde5045985d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e1c3833d-6f41-40e7-9c73-7705bc6775b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d((2, 3), stride=(2, 3), padding=(0, 1))\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3684ae03-7ff5-47dd-b725-5281d1762098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]]],\n",
       "\n",
       "\n",
       "        [[[ 1.,  2.,  3.,  4.],\n",
       "          [ 5.,  6.,  7.,  8.],\n",
       "          [ 9., 10., 11., 12.],\n",
       "          [13., 14., 15., 16.]]]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4))\n",
    "X = torch.cat((X, X + 1), 0)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "89758c1a-4737-488e-8054-dadc3e123381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]],\n",
       "\n",
       "         [[ 1.,  2.,  3.,  4.],\n",
       "          [ 5.,  6.,  7.,  8.],\n",
       "          [ 9., 10., 11., 12.],\n",
       "          [13., 14., 15., 16.]]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4))\n",
    "X = torch.cat((X, X + 1), 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "abc8083b-a9d4-4c14-b518-ea4ee9a76342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.],\n",
       "          [ 1.,  2.,  3.,  4.],\n",
       "          [ 5.,  6.,  7.,  8.],\n",
       "          [ 9., 10., 11., 12.],\n",
       "          [13., 14., 15., 16.]]]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4))\n",
    "X = torch.cat((X, X + 1), 2)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c4cd6fe0-ff08-4d45-bd94-0cfcd649811f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.,  1.,  2.,  3.,  4.],\n",
       "          [ 4.,  5.,  6.,  7.,  5.,  6.,  7.,  8.],\n",
       "          [ 8.,  9., 10., 11.,  9., 10., 11., 12.],\n",
       "          [12., 13., 14., 15., 13., 14., 15., 16.]]]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4))\n",
    "X = torch.cat((X, X + 1), 3)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946202db-5adc-458e-8c50-7888d78144c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
